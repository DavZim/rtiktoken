[{"path":"https://davzim.github.io/rtiktoken/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 rtiktoken authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Zimmermann-Kollenda. Author, maintainer.","code":""},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zimmermann-Kollenda D (2024). rtiktoken: BPE Tokenizer OpenAI's models. R package version 0.0.1, https://davzim.github.io/rtiktoken/.","code":"@Manual{,   title = {rtiktoken: BPE Tokenizer for OpenAI's models},   author = {David Zimmermann-Kollenda},   year = {2024},   note = {R package version 0.0.1},   url = {https://davzim.github.io/rtiktoken/}, }"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"rtiktoken","dir":"","previous_headings":"","what":"BPE Tokenizer for OpenAI's models","title":"BPE Tokenizer for OpenAI's models","text":"rtiktoken thin wrapper around tiktoken-rs (turn around OpenAI’s Python library tiktoken). provides functions encode text tokens used OpenAI’s models decode tokens back text using BPE tokenizers. also useful count numbers tokens text guess expensive call OpenAI’s API . Note tokenization happens offline internet connection required. Another use-case compute similarity scores texts using tokens. use-cases can found OpenAI’s cookbook Count Tokens tiktoken. verify outputs functions, see also OpenAI’s Tokenizer Platform.","code":""},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"BPE Tokenizer for OpenAI's models","text":"can install rtiktoken like :","code":"# Dev version # install.packages(\"devtools\") # devtools::install_github(\"DavZim/rtiktoken\")  # CRAN version install.packages(\"rtiktoken\")"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"BPE Tokenizer for OpenAI's models","text":"","code":"library(rtiktoken)  # 1. Encode text into tokens text <- c(   \"Hello World, this is a text that we are going to use in rtiktoken!\",   \"Note that the functions are vectorized! Yay!\" ) tokens <- get_tokens(text, \"gpt-4o\") tokens #> [[1]] #>  [1] 13225  5922    11   495   382   261  2201   484   581   553  2966   316 #> [13]  1199   306 38742  8251  2488     0 #>  #> [[2]] #>  [1]  12038    484    290   9964    553   9727   2110      0 115915      0  # 2. Decode tokens back into text decoded_text <- decode_tokens(tokens, \"gpt-4o\") decoded_text #> [1] \"Hello World, this is a text that we are going to use in rtiktoken!\" #> [2] \"Note that the functions are vectorized! Yay!\"  # Note that it's not guaranteed to produce the identical text as text-parts # might be dropped if no token match is found. identical(text, decoded_text) #> [1] TRUE  # 3. Count the number of tokens in a text n_tokens <- get_token_count(text, \"gpt-4o\") n_tokens #> [1] 18 10"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"models--tokenizers","dir":"","previous_headings":"Example","what":"Models & Tokenizers","title":"BPE Tokenizer for OpenAI's models","text":"different OpenAI models use different tokenizers (see also source code tikoken-rs full list). following models use following tokenizers (note functions package allow use model names well tokenizer names):","code":""},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"BPE Tokenizer for OpenAI's models","text":"rtiktoken built using extendr Rust. build package, need Rust installed machine.","code":"rextendr::document() devtools::document()"},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Decodes tokens back to text — decode_tokens","title":"Decodes tokens back to text — decode_tokens","text":"Decodes tokens back text","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decodes tokens back to text — decode_tokens","text":"","code":"decode_tokens(tokens, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decodes tokens back to text — decode_tokens","text":"tokens vector tokens decode, list tokens model model use tokenization, either model name, eg gpt-4o tokenizer, eg o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decodes tokens back to text — decode_tokens","text":"character string decoded tokens vector strings","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decodes tokens back to text — decode_tokens","text":"","code":"tokens <- get_tokens(\"Hello World\", \"gpt-4o\") decode_tokens(tokens, \"gpt-4o\") #> [1] \"Hello World\"  tokens <- get_tokens(c(\"Hello World\", \"Alice Bob Charlie\"), \"gpt-4o\") decode_tokens(tokens, \"gpt-4o\") #> [1] \"Hello World\"       \"Alice Bob Charlie\""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the number of tokens in a text — get_token_count","title":"Returns the number of tokens in a text — get_token_count","text":"Returns number tokens text","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the number of tokens in a text — get_token_count","text":"","code":"get_token_count(text, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the number of tokens in a text — get_token_count","text":"text character string encode tokens, can vector model model use tokenization, either model name, eg gpt-4o tokenizer, eg o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the number of tokens in a text — get_token_count","text":"number tokens text, vector ints","code":""},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the number of tokens in a text — get_token_count","text":"","code":"get_token_count(\"Hello World\", \"gpt-4o\") #> [1] 2"},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts text to tokens — get_tokens","title":"Converts text to tokens — get_tokens","text":"Converts text tokens","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts text to tokens — get_tokens","text":"","code":"get_tokens(text, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts text to tokens — get_tokens","text":"text character string encode tokens, can vector model model use tokenization, either model name, eg gpt-4o tokenizer, eg o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts text to tokens — get_tokens","text":"vector tokens given text integer","code":""},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts text to tokens — get_tokens","text":"","code":"get_tokens(\"Hello World\", \"gpt-4o\") #> [1] 13225  5922 get_tokens(\"Hello World\", \"o200k_base\") #> [1] 13225  5922"},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the name of the tokenizer used by a model — model_to_tokenizer","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"Gets name tokenizer used model","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"","code":"model_to_tokenizer(model)"},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"model model use, eg gpt-4o","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"tokenizer used model","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"","code":"model_to_tokenizer(\"gpt-4o\") #> [1] \"o200k_base\" model_to_tokenizer(\"gpt-4-1106-preview\") #> [1] \"cl100k_base\" model_to_tokenizer(\"text-davinci-002\") #> [1] \"p50k_base\" model_to_tokenizer(\"text-embedding-ada-002\") #> [1] \"cl100k_base\" model_to_tokenizer(\"text-embedding-3-small\") #> [1] \"cl100k_base\""},{"path":"https://davzim.github.io/rtiktoken/news/index.html","id":"rtiktoken-01","dir":"Changelog","previous_headings":"","what":"rtiktoken 0.1","title":"rtiktoken 0.1","text":"Initial functionality & tests","code":""}]
