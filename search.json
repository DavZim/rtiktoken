[{"path":"https://davzim.github.io/rtiktoken/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2024 rtiktoken authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"David Zimmermann-Kollenda. Author, maintainer. Roger Zurawicki. Author.           tiktoken-rs Rust library Authors dependent Rust crates. Author.           see AUTHORS file","code":""},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Zimmermann-Kollenda D, Roger Zurawicki, Authors dependent Rust crates (2024). rtiktoken: BPE Tokenizer OpenAI's Models. R package version 0.0.4, https://github.com/DavZim/rtiktoken/, https://davzim.github.io/rtiktoken/.","code":"@Manual{,   title = {rtiktoken: BPE Tokenizer for OpenAI's Models},   author = {David Zimmermann-Kollenda and {Roger Zurawicki} and {Authors of the dependent Rust crates}},   year = {2024},   note = {R package version 0.0.4, https://github.com/DavZim/rtiktoken/},   url = {https://davzim.github.io/rtiktoken/}, }"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"Authors of vendored cargo crates"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- aho-corasick 1.1.3: Andrew Gallant"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- anyhow 1.0.89: David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- autocfg 1.4.0: Josh Stone"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- base64 0.21.7: Alice Maz, Marshall Pierce"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- bit-set 0.5.3: Alexis Beingessner"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- bit-vec 0.6.3: Alexis Beingessner"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- bitflags 2.6.0: The Rust Project Developers"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- bstr 1.10.0: Andrew Gallant"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- cfg-if 1.0.0: Alex Crichton"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- extendr-api 0.7.1: andy-thomason, Thomas Down, Mossa Merhi Reimert, Claus O. Wilke, Hiroaki Yutani, Ilia A. Kosenkov, Michael Milton"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- extendr-macros 0.7.1: andy-thomason, Thomas Down, Mossa Merhi Reimert, Claus O. Wilke, Hiroaki Yutani, Ilia A. Kosenkov, Michael Milton"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- fancy-regex 0.12.0: Raph Levien, Robin Stocker"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- lazy_static 1.5.0: Marvin Löbel"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- libR-sys 0.7.1: andy-thomason, Thomas Down, Mossa Merhi Reimert, Claus O. Wilke, Ilia A. Kosenkov, Hiroaki Yutani"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- libc 0.2.159: The Rust Project Developers"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- lock_api 0.4.12: Amanieu d'Antras"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- memchr 2.7.4: Andrew Gallant, bluss"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- once_cell 1.20.2: Aleksey Kladov"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- parking_lot 0.12.3: Amanieu d'Antras"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- parking_lot_core 0.9.10: Amanieu d'Antras"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- paste 1.0.15: David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- proc-macro2 1.0.87: David Tolnay, Alex Crichton"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- quote 1.0.37: David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- redox_syscall 0.5.7: Jeremy Soller"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- regex 1.11.0: The Rust Project Developers, Andrew Gallant"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- regex-automata 0.4.8: The Rust Project Developers, Andrew Gallant"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- regex-syntax 0.8.5: The Rust Project Developers, Andrew Gallant"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- rustc-hash 1.1.0: The Rust Project Developers"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- scopeguard 1.2.0: bluss"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- serde 1.0.210: Erick Tryzelaar, David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- serde_derive 1.0.210: Erick Tryzelaar, David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- smallvec 1.13.2: The Servo Project Developers"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- syn 2.0.79: David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- tiktoken-rs 0.5.9: Roger Zurawicki"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- unicode-ident 1.0.13: David Tolnay"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows-targets 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_aarch64_gnullvm 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_aarch64_msvc 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_i686_gnu 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_i686_gnullvm 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_i686_msvc 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_x86_64_gnu 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_x86_64_gnullvm 0.52.6: Microsoft"},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"- windows_x86_64_msvc 0.52.6: Microsoft"},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/authors.html","id":null,"dir":"","previous_headings":"","what":"Additional details","title":"Authors and Citation","text":"","code":"(This file was auto-generated from 'cargo metadata' on 2024-10-11)"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"rtiktoken","dir":"","previous_headings":"","what":"BPE Tokenizer for OpenAI's Models","title":"BPE Tokenizer for OpenAI's Models","text":"rtiktoken thin wrapper around tiktoken-rs (turn around OpenAI’s Python library tiktoken). provides functions encode text tokens used OpenAI’s models decode tokens back text using BPE tokenizers. also useful count numbers tokens text guess expensive call OpenAI’s API . Note tokenization happens offline internet connection required. Another use-case compute similarity scores texts using tokens. use-cases can found OpenAI’s cookbook Count Tokens tiktoken. verify outputs functions, see also OpenAI’s Tokenizer Platform.","code":""},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"BPE Tokenizer for OpenAI's Models","text":"can install rtiktoken like :","code":"# Dev version # install.packages(\"devtools\") # devtools::install_github(\"DavZim/rtiktoken\")  # CRAN version install.packages(\"rtiktoken\")"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"BPE Tokenizer for OpenAI's Models","text":"","code":"library(rtiktoken)  # 1. Encode text into tokens text <- c(   \"Hello World, this is a text that we are going to use in rtiktoken!\",   \"Note that the functions are vectorized! Yay!\" ) tokens <- get_tokens(text, \"gpt-4o\") tokens #> [[1]] #>  [1] 13225  5922    11   495   382   261  2201   484   581   553  2966   316 #> [13]  1199   306 38742  8251  2488     0 #>  #> [[2]] #>  [1]  12038    484    290   9964    553   9727   2110      0 115915      0  # 2. Decode tokens back into text decoded_text <- decode_tokens(tokens, \"gpt-4o\") decoded_text #> [1] \"Hello World, this is a text that we are going to use in rtiktoken!\" #> [2] \"Note that the functions are vectorized! Yay!\"  # Note that it's not guaranteed to produce the identical text as text-parts # might be dropped if no token match is found. identical(text, decoded_text) #> [1] TRUE  # 3. Count the number of tokens in a text n_tokens <- get_token_count(text, \"gpt-4o\") n_tokens #> [1] 18 10"},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"models--tokenizers","dir":"","previous_headings":"Example","what":"Models & Tokenizers","title":"BPE Tokenizer for OpenAI's Models","text":"different OpenAI models use different tokenizers (see also source code tikoken-rs full list). following models use following tokenizers (note functions package allow use model names well tokenizer names):","code":""},{"path":"https://davzim.github.io/rtiktoken/index.html","id":"development","dir":"","previous_headings":"","what":"Development","title":"BPE Tokenizer for OpenAI's Models","text":"rtiktoken built using extendr Rust. build package, need Rust installed machine.","code":"rextendr::document() devtools::document()"},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Decodes tokens back to text — decode_tokens","title":"Decodes tokens back to text — decode_tokens","text":"Decodes tokens back text","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Decodes tokens back to text — decode_tokens","text":"","code":"decode_tokens(tokens, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Decodes tokens back to text — decode_tokens","text":"tokens vector tokens decode, list tokens model model use tokenization, either model name, e.g., gpt-4o tokenizer, e.g., o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Decodes tokens back to text — decode_tokens","text":"character string decoded tokens vector strings","code":""},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/reference/decode_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Decodes tokens back to text — decode_tokens","text":"","code":"tokens <- get_tokens(\"Hello World\", \"gpt-4o\") tokens #> [1] 13225  5922 decode_tokens(tokens, \"gpt-4o\") #> [1] \"Hello World\"  tokens <- get_tokens(c(\"Hello World\", \"Alice Bob Charlie\"), \"gpt-4o\") tokens #> [[1]] #> [1] 13225  5922 #>  #> [[2]] #> [1] 100151  22582  41704 #>  decode_tokens(tokens, \"gpt-4o\") #> [1] \"Hello World\"       \"Alice Bob Charlie\""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Returns the number of tokens in a text — get_token_count","title":"Returns the number of tokens in a text — get_token_count","text":"Returns number tokens text","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Returns the number of tokens in a text — get_token_count","text":"","code":"get_token_count(text, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Returns the number of tokens in a text — get_token_count","text":"text character string encode tokens, can vector model model use tokenization, either model name, e.g., gpt-4o tokenizer, e.g., o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Returns the number of tokens in a text — get_token_count","text":"number tokens text, vector integers","code":""},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/reference/get_token_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Returns the number of tokens in a text — get_token_count","text":"","code":"get_token_count(\"Hello World\", \"gpt-4o\") #> [1] 2"},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":null,"dir":"Reference","previous_headings":"","what":"Converts text to tokens — get_tokens","title":"Converts text to tokens — get_tokens","text":"Converts text tokens","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Converts text to tokens — get_tokens","text":"","code":"get_tokens(text, model)"},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Converts text to tokens — get_tokens","text":"text character string encode tokens, can vector model model use tokenization, either model name, e.g., gpt-4o tokenizer, e.g., o200k_base. See also available tokenizers.","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Converts text to tokens — get_tokens","text":"vector tokens given text integer","code":""},{"path":[]},{"path":"https://davzim.github.io/rtiktoken/reference/get_tokens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Converts text to tokens — get_tokens","text":"","code":"get_tokens(\"Hello World\", \"gpt-4o\") #> [1] 13225  5922 get_tokens(\"Hello World\", \"o200k_base\") #> [1] 13225  5922"},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":null,"dir":"Reference","previous_headings":"","what":"Gets the name of the tokenizer used by a model — model_to_tokenizer","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"Gets name tokenizer used model","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"","code":"model_to_tokenizer(model)"},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"model model use, e.g., gpt-4o","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"tokenizer used model","code":""},{"path":"https://davzim.github.io/rtiktoken/reference/model_to_tokenizer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gets the name of the tokenizer used by a model — model_to_tokenizer","text":"","code":"model_to_tokenizer(\"gpt-4o\") #> [1] \"o200k_base\" model_to_tokenizer(\"gpt-4-1106-preview\") #> [1] \"cl100k_base\" model_to_tokenizer(\"text-davinci-002\") #> [1] \"p50k_base\" model_to_tokenizer(\"text-embedding-ada-002\") #> [1] \"cl100k_base\" model_to_tokenizer(\"text-embedding-3-small\") #> [1] \"cl100k_base\""},{"path":"https://davzim.github.io/rtiktoken/news/index.html","id":"rtiktoken-03-04","dir":"Changelog","previous_headings":"","what":"rtiktoken 0.3, 0.4","title":"rtiktoken 0.3, 0.4","text":"fix build CRAN","code":""},{"path":"https://davzim.github.io/rtiktoken/news/index.html","id":"rtiktoken-02","dir":"Changelog","previous_headings":"","what":"rtiktoken 0.2","title":"rtiktoken 0.2","text":"fix Notes Warning CRAN release","code":""},{"path":"https://davzim.github.io/rtiktoken/news/index.html","id":"rtiktoken-01","dir":"Changelog","previous_headings":"","what":"rtiktoken 0.1","title":"rtiktoken 0.1","text":"Initial functionality & tests","code":""}]
